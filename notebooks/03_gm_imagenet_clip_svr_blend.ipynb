{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12648854-f01d-4f49-9a87-3f1c93a27152",
   "metadata": {},
   "source": [
    "### Imports & I/O setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbb8178-a74a-4ab1-aa9a-cb75f6824b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Train/Test shapes: (9912, 16) (8, 14)\n",
      "            mean        std  count\n",
      "fold0                             \n",
      "0      38.070565  20.609429    496\n",
      "1      38.266129  20.688008    496\n",
      "2      38.032258  20.430591    496\n",
      "3      38.042339  20.532709    496\n",
      "4      37.973790  20.560168    496\n",
      "[info] Will use 10 feature sets: ['clip_RN50x4', 'clip_RN50x16', 'clip_ViT-B-16', 'clip_ViT-B-32', 'ig_resnext101_32x48d', 'ig_resnext101_32x48d_hflip_384', 'deit_base_distilled_patch16_384_hflip_384', 'tf_efficientnet_l2_ns_hflip_384', 'tf_efficientnet_l2_ns_512', 'vit_large_r50_s32_384']\n",
      "[feat] clip_RN50x4                               train (9912, 640)  test (8, 640)\n",
      "[feat] clip_RN50x16                              train (9912, 768)  test (8, 768)\n",
      "[feat] clip_ViT-B-16                             train (9912, 512)  test (8, 512)\n",
      "[feat] clip_ViT-B-32                             train (9912, 512)  test (8, 512)\n",
      "[feat] ig_resnext101_32x48d                      train (9912, 1000)  test (8, 1000)\n",
      "[feat] ig_resnext101_32x48d_hflip_384            train (9912, 1000)  test (8, 1000)\n",
      "[feat] deit_base_distilled_patch16_384_hflip_384  train (9912, 1000)  test (8, 1000)\n",
      "[feat] tf_efficientnet_l2_ns_hflip_384           train (9912, 1000)  test (8, 1000)\n",
      "[feat] tf_efficientnet_l2_ns_512                 train (9912, 1000)  test (8, 1000)\n",
      "[feat] vit_large_r50_s32_384                     train (9912, 1000)  test (8, 1000)\n",
      "[info] Concatenated: (9912, 8432) (8, 8432)\n",
      "[info] Using GPU cuML SVR\n",
      "[CV] RMSE: 17.05617904663086\n",
      "[done] Wrote /workspace/pet-finder/notebooks/submission.csv  shape=(8, 2)\n"
     ]
    }
   ],
   "source": [
    "import os, gc, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---- Paths (match your screenshots) ----\n",
    "ROOT       = \"/workspace/pet-finder\"\n",
    "BASE       = f\"{ROOT}/data/raw\"        # csv + image folders\n",
    "PROCESSED  = f\"{ROOT}/data/processed\"  # feature .npy files\n",
    "OUT_DIR    = f\"{ROOT}/notebooks\"\n",
    "\n",
    "for p in [BASE, PROCESSED, OUT_DIR]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# Hard checks so we fail fast if something is off\n",
    "assert os.path.exists(f\"{BASE}/train.csv\"), f\"Missing {BASE}/train.csv\"\n",
    "assert os.path.exists(f\"{BASE}/test.csv\"),  f\"Missing {BASE}/test.csv\"\n",
    "\n",
    "# ---- Folds (saved in processed/) ----\n",
    "def make_stratified_folds(base_dir=BASE, out_path=f\"{PROCESSED}/train-folds-1.csv\",\n",
    "                          n_splits=20, seed=1):\n",
    "    df = pd.read_csv(f\"{base_dir}/train.csv\")\n",
    "    df[\"bins\"]  = (df[\"Pawpularity\"] // 5).astype(int)\n",
    "    df[\"fold0\"] = -1\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for i, (_, val_idx) in enumerate(skf.split(df.index, df[\"bins\"])):\n",
    "        df.loc[val_idx, \"fold0\"] = i\n",
    "    df.drop(columns=[\"bins\"], inplace=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    return df\n",
    "\n",
    "folds_csv = f\"{PROCESSED}/train-folds-1.csv\"\n",
    "train = pd.read_csv(folds_csv) if os.path.exists(folds_csv) else make_stratified_folds()\n",
    "test  = pd.read_csv(f\"{BASE}/test.csv\")\n",
    "\n",
    "# Attach image paths (not strictly needed for SVR-only)\n",
    "train[\"path\"] = train[\"Id\"].map(lambda x: os.path.join(BASE, \"train\", f\"{x}.jpg\"))\n",
    "test[\"path\"]  = test[\"Id\"].map(lambda x: os.path.join(BASE, \"test\",  f\"{x}.jpg\"))\n",
    "\n",
    "print(\"[info] Train/Test shapes:\", train.shape, test.shape)\n",
    "print(train.groupby(\"fold0\")[\"Pawpularity\"].agg([\"mean\",\"std\",\"count\"]).head())\n",
    "\n",
    "# ---- Which feature sets to use ----\n",
    "# These are the GM picks. We'll auto-skip any that you haven't saved yet.\n",
    "CANDIDATES = [\n",
    "    # CLIP\n",
    "    \"clip_RN50x4\", \"clip_RN50x16\", \"clip_ViT-B-16\", \"clip_ViT-B-32\",\n",
    "    # TIMM logits (as in the GM notebook)\n",
    "    \"ig_resnext101_32x48d\",\n",
    "    \"ig_resnext101_32x48d_hflip_384\",\n",
    "    \"deit_base_distilled_patch16_384_hflip_384\",\n",
    "    \"tf_efficientnet_l2_ns_hflip_384\",\n",
    "    \"tf_efficientnet_l2_ns_512\",\n",
    "    \"vit_large_r50_s32_384\",\n",
    "]\n",
    "\n",
    "def feature_pair_exists(name):\n",
    "    return (os.path.exists(f\"{PROCESSED}/{name}_train.npy\")\n",
    "            and os.path.exists(f\"{PROCESSED}/{name}_test.npy\"))\n",
    "\n",
    "USE = [n for n in CANDIDATES if feature_pair_exists(n)]\n",
    "missing = [n for n in CANDIDATES if n not in USE]\n",
    "print(f\"[info] Will use {len(USE)} feature sets:\", USE)\n",
    "if missing:\n",
    "    print(f\"[warn] Skipping (files not found): {missing}\")\n",
    "\n",
    "# ---- Load features ----\n",
    "def load_feats(name):\n",
    "    tr = np.load(f\"{PROCESSED}/{name}_train.npy\", allow_pickle=False)\n",
    "    te = np.load(f\"{PROCESSED}/{name}_test.npy\",  allow_pickle=False)\n",
    "    # Ensure 2D\n",
    "    if tr.ndim == 1: tr = tr[:, None]\n",
    "    if te.ndim == 1: te = te[:, None]\n",
    "    return tr.astype(\"float32\"), te.astype(\"float32\")\n",
    "\n",
    "TR_blocks, TE_blocks = [], []\n",
    "for n in USE:\n",
    "    tr, te = load_feats(n)\n",
    "    assert tr.shape[0] == len(train), f\"{n}: train rows mismatch\"\n",
    "    assert te.shape[0] == len(test),  f\"{n}: test rows mismatch\"\n",
    "    TR_blocks.append(tr); TE_blocks.append(te)\n",
    "    print(f\"[feat] {n:40s}  train {tr.shape}  test {te.shape}\")\n",
    "\n",
    "TRAIN = np.concatenate(TR_blocks, axis=1)\n",
    "TEST  = np.concatenate(TE_blocks, axis=1)\n",
    "print(\"[info] Concatenated:\", TRAIN.shape, TEST.shape)\n",
    "\n",
    "# ---- Standardize (fit on train+test, like the GM notebook) ----\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(np.vstack([TRAIN, TEST]))\n",
    "TRAIN = scaler.transform(TRAIN)\n",
    "TEST  = scaler.transform(TEST)\n",
    "gc.collect()\n",
    "\n",
    "# ---- SVR (GPU via cuML if available, else sklearn fallback) ----\n",
    "try:\n",
    "    from cuml.svm import SVR as cuSVR\n",
    "    SVRImpl = cuSVR\n",
    "    svr_kwargs = dict(C=16.0, kernel=\"rbf\", degree=3, max_iter=4000, output_type=\"numpy\")\n",
    "    gpu = True\n",
    "except Exception as e:\n",
    "    from sklearn.svm import SVR as skSVR\n",
    "    SVRImpl = skSVR\n",
    "    svr_kwargs = dict(C=16.0, kernel=\"rbf\", degree=3, max_iter=4000)\n",
    "    gpu = False\n",
    "print(f\"[info] Using {'GPU cuML' if gpu else 'CPU sklearn'} SVR\")\n",
    "\n",
    "def rmse(y, p): return float(np.sqrt(np.mean((y - p)**2)))\n",
    "\n",
    "def fit_svr_oof(TR, TE, y, folds_col=\"fold0\"):\n",
    "    oof = np.zeros(TR.shape[0], dtype=\"float32\")\n",
    "    pred = np.zeros(TE.shape[0], dtype=\"float32\")\n",
    "    nfolds = int(train[folds_col].max()) + 1\n",
    "    for f in range(nfolds):\n",
    "        tr_idx = train[folds_col].values != f\n",
    "        va_idx = train[folds_col].values == f\n",
    "        model = SVRImpl(**svr_kwargs)\n",
    "        model.fit(TR[tr_idx], np.clip(y[tr_idx], 1, 85))\n",
    "        oof[va_idx] = np.clip(model.predict(TR[va_idx]), 1, 100)\n",
    "        pred     += np.clip(model.predict(TE), 1, 100) / nfolds\n",
    "        del model; gc.collect()\n",
    "    return oof, pred\n",
    "\n",
    "y = train[\"Pawpularity\"].values.astype(\"float32\")\n",
    "oof, test_pred = fit_svr_oof(TRAIN, TEST, y, \"fold0\")\n",
    "print(\"[CV] RMSE:\", rmse(y, oof))\n",
    "\n",
    "# ---- Write submission ----\n",
    "sub = pd.DataFrame({\"Id\": test[\"Id\"].values, \"Pawpularity\": test_pred})\n",
    "out_csv = os.path.join(OUT_DIR, \"submission.csv\")\n",
    "sub.to_csv(out_csv, index=False)\n",
    "print(f\"[done] Wrote {out_csv}  shape={sub.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a2a0d-dbd0-4ebd-9794-51761ed1a5cd",
   "metadata": {},
   "source": [
    "### Save SVR OOF/TEST preds (so we can blend later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f190f4c5-414d-4ced-97ff-ca9d826aad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] oof_svr_gm.npy / test_svr_gm.npy / oof_svr_gm.csv\n"
     ]
    }
   ],
   "source": [
    "# Save SVR predictions so we can reuse / blend\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "ROOT      = \"/workspace/pet-finder\"\n",
    "BASE      = f\"{ROOT}/data/raw\"\n",
    "PROCESSED = f\"{ROOT}/data/processed\"\n",
    "NOTEBOOKS = f\"{ROOT}/notebooks\"\n",
    "os.makedirs(PROCESSED, exist_ok=True)\n",
    "\n",
    "# `oof` and `test_pred` come from the previous cell you just ran\n",
    "np.save(f\"{PROCESSED}/oof_svr_gm.npy\",  oof.astype(\"float32\"))\n",
    "np.save(f\"{PROCESSED}/test_svr_gm.npy\", test_pred.astype(\"float32\"))\n",
    "\n",
    "# also save an OOF csv with Id,pred (handy for quick checks)\n",
    "pd.DataFrame({\"Id\": train[\"Id\"].values, \"pred\": oof}).to_csv(\n",
    "    f\"{PROCESSED}/oof_svr_gm.csv\", index=False\n",
    ")\n",
    "\n",
    "print(\"[saved] oof_svr_gm.npy / test_svr_gm.npy / oof_svr_gm.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00fabee-c814-480a-982d-f010bb7394a1",
   "metadata": {},
   "source": [
    "### Build the feature bank (GM set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd27e36-826d-4a82-9421-c88debda8ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[blend] found sources: ['svr_gm', 'svr_gm']\n",
      "[blend] optimiser: scipy  weights -> {'svr_gm': 0.5}\n",
      "[blend] CV RMSE: 17.056179619467798\n",
      "[done] wrote /workspace/pet-finder/notebooks/submission_blend.csv  shape=(8, 2)\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np, pandas as pd, gc\n",
    "\n",
    "ROOT      = \"/workspace/pet-finder\"\n",
    "BASE      = f\"{ROOT}/data/raw\"\n",
    "PROCESSED = f\"{ROOT}/data/processed\"\n",
    "NOTEBOOKS = f\"{ROOT}/notebooks\"\n",
    "\n",
    "train = pd.read_csv(f\"{PROCESSED}/train-folds-1.csv\")\n",
    "test  = pd.read_csv(f\"{BASE}/test.csv\")\n",
    "y     = train[\"Pawpularity\"].values.astype(\"float32\")\n",
    "\n",
    "# Always include our SVR\n",
    "sources = [{\"name\":\"svr_gm\",\n",
    "            \"oof\": np.load(f\"{PROCESSED}/oof_svr_gm.npy\"),\n",
    "            \"test\":np.load(f\"{PROCESSED}/test_svr_gm.npy\")}]\n",
    "\n",
    "# Auto-discover extra (tag = filename after 'oof_' and before '.csv')\n",
    "for oof_csv in glob.glob(f\"{PROCESSED}/oof_*.csv\"):\n",
    "    tag = os.path.basename(oof_csv)[len(\"oof_\"):-len(\".csv\")]\n",
    "    test_npy = f\"{PROCESSED}/test_{tag}.npy\"\n",
    "    if os.path.exists(test_npy):\n",
    "        oof_df = pd.read_csv(oof_csv)\n",
    "        if {\"Id\",\"pred\"}.issubset(oof_df.columns):\n",
    "            # align to train order\n",
    "            oof = train[[\"Id\"]].merge(oof_df, on=\"Id\", how=\"left\")[\"pred\"].values.astype(\"float32\")\n",
    "            tst = np.load(test_npy).astype(\"float32\")\n",
    "            if len(oof)==len(train) and len(tst)==len(test):\n",
    "                sources.append({\"name\":tag, \"oof\":oof, \"test\":tst})\n",
    "\n",
    "print(\"[blend] found sources:\", [s[\"name\"] for s in sources])\n",
    "\n",
    "# Build matrices\n",
    "OOF_M = np.stack([s[\"oof\"]  for s in sources], axis=1)\n",
    "TST_M = np.stack([s[\"test\"] for s in sources], axis=1)\n",
    "\n",
    "def rmse(y, p): return float(np.sqrt(np.mean((y - p)**2)))\n",
    "\n",
    "# ---- weight optimisation (non-negative, sum-to-1 if SciPy available) ----\n",
    "def normalise_nonneg(w):\n",
    "    w = np.clip(w, 0, None)\n",
    "    s = w.sum()\n",
    "    return w/s if s>0 else np.ones_like(w)/len(w)\n",
    "\n",
    "try:\n",
    "    from scipy.optimize import minimize\n",
    "\n",
    "    def obj(w):\n",
    "        w = normalise_nonneg(w)\n",
    "        return rmse(y, OOF_M @ w)\n",
    "\n",
    "    w0 = np.ones(OOF_M.shape[1]) / OOF_M.shape[1]\n",
    "    res = minimize(obj, w0, method=\"Nelder-Mead\", tol=1e-8, options={\"maxiter\": 2000})\n",
    "    W = normalise_nonneg(res.x)\n",
    "    used = \"scipy\"\n",
    "except Exception:\n",
    "    # fallback: ridge to get weights, then clamp to nonneg & renormalise\n",
    "    X = OOF_M\n",
    "    lam = 1e-6\n",
    "    W = np.linalg.solve(X.T@X + lam*np.eye(X.shape[1]), X.T@y)\n",
    "    W = normalise_nonneg(W)\n",
    "    used = \"ridge-fallback\"\n",
    "\n",
    "print(f\"[blend] optimiser: {used}  weights ->\",\n",
    "      {sources[i][\"name\"]: float(W[i]) for i in range(len(sources))})\n",
    "print(\"[blend] CV RMSE:\", rmse(y, OOF_M @ W))\n",
    "\n",
    "# final test predictions\n",
    "final_test = TST_M @ W\n",
    "\n",
    "# (Optional) GM tip: a tiny up-scale sometimes helps (SVR targets were clipped)\n",
    "# final_test *= 1.032\n",
    "\n",
    "# write blended submission alongside the plain SVR one\n",
    "sub_blend = pd.DataFrame({\"Id\": test[\"Id\"].values, \"Pawpularity\": final_test})\n",
    "out_csv = f\"{NOTEBOOKS}/submission_blend.csv\"\n",
    "sub_blend.to_csv(out_csv, index=False)\n",
    "print(f\"[done] wrote {out_csv}  shape={sub_blend.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
